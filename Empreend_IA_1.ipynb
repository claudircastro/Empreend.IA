{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuvK_vaIPzTp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KFAPmGPtO_LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbde7d2e-09c1-4e51-c08a-521f48c640e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.1/217.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Instalar as bibliotecas necessárias (rode no colab)\n",
        "!pip install -U google-genai -q\n",
        "!pip install -q google-adk\n",
        "\n",
        "# Importações e configuração\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai  # Biblioteca oficial para Gemini (genai)\n",
        "\n",
        "# Configuração dos tools disponíveis no modelo Gemini (só o nome da ferramenta)\n",
        "TOOLS = [\"google_search\"]\n",
        "\n",
        "# Quebrando o Texto por Linhas\n",
        "from IPython.display import HTML, Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "# Configurar chave da API do Gemini\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "\n",
        "# Importações do ADK\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.genai import types # This import is for types, not the main model\n",
        "from datetime import date\n",
        "import ast  # Segurança ao avaliar dicionários do agente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xIAPOdOrPJ0n"
      },
      "outputs": [],
      "source": [
        "#função auxiliar chamar agentes\n",
        "def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    session_service = InMemorySessionService()\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=\"user1\", session_id=\"session1\")\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "    final_response = \"\"\n",
        "    for event in runner.run(user_id=\"user1\", session_id=\"session1\", new_message=content):\n",
        "        if event.is_final_response():\n",
        "            for part in event.content.parts:\n",
        "                if part.text:\n",
        "                    final_response += part.text + \"\\n\"\n",
        "    return final_response\n",
        "\n",
        "# MEMÓRIA GLOBAL (pode ser exportada para JSON, Planilha, etc.)\n",
        "perfil_usuario = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "E3guyPTPOFYs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DICIONÁRIO\n",
        "# melhorar: criar em um arquivo externo .py\n",
        "metodos_produtividade = {\n",
        "    \"GTD\": {\n",
        "        \"organizacao\": [\"metas\", \"livre\"],\n",
        "        \"descricao\": (\n",
        "            \"O método Getting Things Done (GTD) foca em capturar todas as tarefas e compromissos \"\n",
        "            \"fora da mente, organizá-los em listas específicas e revisá-los regularmente para aumentar a produtividade.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"Liste todas as suas tarefas, categorize-as por contexto (ex: 'telefonemas', 'compras'), \"\n",
        "            \"e revise semanalmente para priorizar o que deve ser feito.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Todoist\", \"Evernote\", \"Notion\"]\n",
        "    },\n",
        "    \"Ivy Lee\": {\n",
        "        \"organizacao\": [\"metas\", \"time_blocking\"],\n",
        "        \"descricao\": (\n",
        "            \"Método simples que prioriza até 6 tarefas importantes para o dia seguinte, \"\n",
        "            \"executando-as em ordem, ajudando a focar no essencial.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"No final do dia, escreva as 6 tarefas mais importantes para amanhã, \"\n",
        "            \"comece pela primeira e só passe para a próxima quando terminar.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Bloco de notas\", \"Todoist\"]\n",
        "    },\n",
        "    \"Pomodoro\": {\n",
        "        \"organizacao\": [\"time_blocking\", \"livre\"],\n",
        "        \"descricao\": (\n",
        "            \"Trabalhar em blocos de tempo focado de 25 minutos, seguidos por pausas curtas, \"\n",
        "            \"aumentando a concentração e prevenindo fadiga.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"Configure um timer para 25 minutos e trabalhe sem distrações. \"\n",
        "            \"Após o alarme, faça uma pausa de 5 minutos. Repita 4 vezes e faça uma pausa maior.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Pomodone\", \"TomatoTimer\", \"Forest\"]\n",
        "    },\n",
        "    \"Kanban\": {\n",
        "        \"organizacao\": [\"to_do\", \"livre\"],\n",
        "        \"descricao\": (\n",
        "            \"Sistema visual que organiza tarefas em colunas como 'A fazer', 'Fazendo' e 'Feito', \"\n",
        "            \"facilitando o acompanhamento do fluxo de trabalho.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"Crie cartões para cada tarefa e mova-os entre as colunas conforme o progresso, \"\n",
        "            \"visualizando claramente o status das atividades.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Trello\", \"Asana\", \"ClickUp\"]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "uRLXdOuEhdcT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Função de busca usando Gemini com Google Search tool\n",
        "def buscar_com_google_gemini(query: str):\n",
        "    # Cria o modelo Gemini com a ferramenta google_search ativada\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name=\"gemini-1.5-pro-latest\",\n",
        "        tools=[{\"name\": \"google_search\"}]  # Apenas 'name' da ferramenta, sem 'type'\n",
        "    )\n",
        "    # Gera o conteúdo usando o prompt e ativando a função de busca\n",
        "    response = model.generate_content(query)\n",
        "    return response.text\"\"\"\n",
        "\n",
        "def buscar_com_google_gemini(query: str):\n",
        "  model = genai.GenerativeModel(\n",
        "      model_name=\"gemini-1.5-pro-latest\",\n",
        "      tools=[{\"name\": \"google_search\"}]\n",
        "  )\n",
        "\n",
        "  # Limita tamanho do prompt a 500 caracteres (ajustável)\n",
        "  query_limpa = query.strip()[:500]\n",
        "\n",
        "  try:\n",
        "      response = model.generate_content(query_limpa)\n",
        "      return response.text\n",
        "  except Exception as e:\n",
        "      return f\"Erro ao buscar: {e}\""
      ],
      "metadata": {
        "id": "vz3X8h_fpGJV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SeEq7lo5Ptu3"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO ENTREVISTA\n",
        "def entrevista_interativa():\n",
        "    respostas = {}\n",
        "\n",
        "    perguntas = {\n",
        "        \"segmento\": \"1. Qual é o segmento principal da sua empresa? (Ex: Alimentação, Moda, Tecnologia, Serviços, etc.)\",\n",
        "        \"tipo_negocio\": \"2. Seu tipo de negócio se encaixa mais como: e-commerce, venda de produtos físicos, prestação de serviços, consultoria, ou outro?\",\n",
        "        \"objetivo\": \"3. Qual é o seu principal objetivo para o seu negócio neste momento? (Ex: Aumentar vendas, organizar minhas finanças, melhorar meu marketing, otimizar meu tempo, etc.)\",\n",
        "        \"organizacao\": \"4. Pensando em como você geralmente lida com suas tarefas e seu tempo, qual das opções abaixo descreve melhor seu estilo de produtividade?\\n\\\n",
        "a) Focado em metas\\nb) Organizado por tempo\\nc) Flexível e adaptável\\nd) Orientado por listas\"\n",
        "    }\n",
        "    for chave, pergunta in perguntas.items():\n",
        "        resposta = input(pergunta + \"\\n> \")\n",
        "        respostas[chave] = resposta\n",
        "\n",
        "    return respostas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JNrZ2Qn3UTpv"
      },
      "outputs": [],
      "source": [
        "# AGENTE 1 - PERFILADOR\n",
        "# melhorar: coletar informações durante qualquer interação (de forma dinamica) para adicionar novas variaveis dentro de perfil\n",
        "def agente_classificador_de_perfil(respostas):\n",
        "    \"\"\"\n",
        "    Interpreta e classifica as respostas da entrevista_interativa() com base em perfis padronizados.\n",
        "    Retorna um dicionário com labels estruturados.\n",
        "    \"\"\"\n",
        "    perfil = {}\n",
        "\n",
        "    # Segmento (mantém texto original do usuário)\n",
        "    segmento = respostas.get(\"segmento\", \"\").strip()\n",
        "    perfil[\"segmento\"] = segmento\n",
        "\n",
        "    #Tipo de negócio\n",
        "    tipo = respostas.get(\"tipo_negocio\", \"\").lower()\n",
        "    # Categorias com palavras relacionadas\n",
        "    palavras_produto = [\"produto\", \"produtos\", \"fabricação\", \"fabricacao\", \"industrial\"]\n",
        "    palavras_servico = [\"serviço\", \"servico\", \"prestação\", \"consultoria\", \"atendimento\", \"freelancer\"]\n",
        "    palavras_online = [\"e-commerce\", \"loja virtual\", \"digital\", \"online\", \"marketplace\"]\n",
        "    palavras_fisico = [\"físico\", \"fisico\", \"loja física\", \"presencial\", \"ponto de venda\"]\n",
        "\n",
        "    # Verifica a qual categoria pertence\n",
        "    if any(p in tipo for p in palavras_produto):\n",
        "        perfil[\"tipo_negocio\"] = \"produto\"\n",
        "    elif any(p in tipo for p in palavras_servico):\n",
        "        perfil[\"tipo_negocio\"] = \"servico\"\n",
        "    elif any(p in tipo for p in palavras_online):\n",
        "        perfil[\"tipo_negocio\"] = \"online\"\n",
        "    elif any(p in tipo for p in palavras_fisico):\n",
        "        perfil[\"tipo_negocio\"] = \"fisico\"\n",
        "    else:\n",
        "        perfil[\"tipo_negocio\"] = \"hibrido\"\n",
        "\n",
        "    # Objetivo\n",
        "    objetivo = respostas.get(\"objetivo\", \"\").lower()\n",
        "    if \"vender\" in objetivo:\n",
        "        perfil[\"objetivo\"] = \"vender_mais\"\n",
        "    elif \"organizar\" in objetivo or \"rotina\" in objetivo:\n",
        "        perfil[\"objetivo\"] = \"organizar_rotina\"\n",
        "    elif \"tempo\" in objetivo or \"automatizar\" in objetivo:\n",
        "        perfil[\"objetivo\"] = \"ganhar_tempo\"\n",
        "    else:\n",
        "        perfil[\"objetivo\"] = \"neutro\"\n",
        "\n",
        "    # Estilo de organização\n",
        "    org = respostas.get(\"organizacao\", \"\").lower().strip()\n",
        "\n",
        "    if org.startswith(\"b\"):\n",
        "        perfil[\"organizacao\"] = \"time_blocking\"\n",
        "    elif org.startswith(\"a\"):\n",
        "        perfil[\"organizacao\"] = \"metas\"\n",
        "    elif org.startswith(\"d\"):\n",
        "        perfil[\"organizacao\"] = \"to_do\"\n",
        "    elif org.startswith(\"c\"):\n",
        "        perfil[\"organizacao\"] = \"livre\"\n",
        "    else:\n",
        "        perfil[\"organizacao\"] = \"indefinido\"\n",
        "\n",
        "    def adicionar_metodo(perfil, metodos_produtividade):\n",
        "      # Seleciona os métodos baseado na organização\n",
        "      organizacao = perfil.get(\"organizacao\", \"\")\n",
        "      metodos_para_organizacao = [\n",
        "          metodo for metodo, dados in metodos_produtividade.items()\n",
        "          if organizacao in dados[\"perfil_indicado\"]\n",
        "      ]\n",
        "      # Atualiza o perfil com os métodos encontrados ou usa [\"GTD\"] como padrão\n",
        "      perfil[\"metodos_produtividade\"] = metodos_para_organizacao or [\"GTD\"]\n",
        "\n",
        "    return perfil\n",
        "    print (to_markdown(perfil))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "K72E_M_OSjIz"
      },
      "outputs": [],
      "source": [
        "# AGENTE 2 APRESENTADOR\n",
        "def agente_apresentador_de_perfil(perfil_usuario):\n",
        "    agente = Agent(\n",
        "        name=\"agente_apresentador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Você é um assistente pessoal empático e inteligente.\n",
        "        Sua missão é ler o perfil de um empreendedor e:\n",
        "\n",
        "        1. Fazer um comentário breve, simpático e acolhedor sobre o estilo da pessoa.\n",
        "        2. Mostrar que você compreende o contexto e o ramo de atuação dela.\n",
        "        3. Reafirmar que todas as suas respostas a partir de agora serão adaptadas a esse perfil.\n",
        "        4. Perguntar, com naturalidade e leveza, o que ela precisa resolver HOJE.\n",
        "\n",
        "        Use linguagem clara, respeitosa e personalizada.\n",
        "        Adapte o tom da resposta conforme o estilo de foco ou organização do usuário.\n",
        "        Pode usar emojis se o perfil sugerir algo mais informal.\n",
        "        Evite parecer robótico. Soe como alguém que entende gente de verdade.\n",
        "        \"\"\",\n",
        "        description=\"Apresentador de perfil e primeiro contato amigável com o usuário\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"Perfil do usuário:\\n{perfil_usuario}\"\n",
        "    print(\"🌟 Apresentando o perfil e iniciando o atendimento personalizado...\\n\")\n",
        "    resposta = call_agent(agente, prompt)\n",
        "    print(resposta)\n",
        "    return to_markdown(resposta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lWcA4tcZcnNK"
      },
      "outputs": [],
      "source": [
        "# AGENTE 3 EXECUTOR\n",
        "def agente_executor_personalizado(pedido_usuario: str, perfil: dict) -> str:\n",
        "    agente = Agent(\n",
        "        name=\"agente_executor_personalizado\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        # melhorar: data dinamica\n",
        "        instruction=f\"\"\" Você é um assistente prático e visionário, feito para apoiar pequenos empreendedores brasileiros com base nas tendências mais recentes (até maio de 2025)\n",
        "         e orientações do Sebrae. Use um tom encorajador e, quando apropriado, um toque de humor leve para motivar.\n",
        "\n",
        "        → Baseie suas respostas no perfil do usuário:\n",
        "          - Organização: {perfil.get('organizacao')}\n",
        "          - Tipo de negócio: {perfil.get('tipo_negocio')}\n",
        "          - Segmento: {perfil.get('segmento')}\n",
        "          - Objetivo principal: {perfil.get('objetivo')}\n",
        "          - Metodos de produtividade recomendados: {perfil.get('metodos_produtividade')}\n",
        "\n",
        "        → Adapte sua comunicação com base nesses perfis. Use uma tabela interna para modular tom, formato e sugestões.\n",
        "\n",
        "        → Sempre que o tema permitir, pergunte sutilmente sobre ações sustentáveis no negócio. Enfatize que empresas comprometidas com o planeta tendem a liderar o futuro do mercado.\n",
        "\n",
        "        → Seja sempre:\n",
        "          - Claro e conciso (respostas curtas, sem floreios)\n",
        "          - Personalizado (nada genérico)\n",
        "          - Focado em ação prática, metas e acompanhamento\n",
        "          - Atualizado com dados do Sebrae, tendências digitais e comportamento do consumidor\n",
        "\n",
        "        → Incentive:\n",
        "          - Participação em conselhos e redes de apoio locais\n",
        "          - Cursos e capacitações\n",
        "          - Inovação constante\n",
        "          - O associativismo como caminho de crescimento\n",
        "\n",
        "       → Se o pedido estiver incompleto ou muito geral, utilize seu conhecimento sobre o perfil e incentive o usuário a dar mais contexto com leveza — mas continue ajudando com o que for possível.\n",
        "      → Se o metodo de produtividade do usuário for conhecido, você pode sugerir um método que combine com ele e com a solicitação que ele te fez. Use linguagem leve, como: Nesse caso, talvez o método X funcione bem pra você.\n",
        "      Pedido do usuário: \"{pedido_usuario}\"\n",
        "        \"\"\",\n",
        "        description=\"Executor Personalizado: adapta respostas e sugestões ao perfil do empreendedor\"\n",
        "    )\n",
        "\n",
        "    resposta = call_agent(agente, pedido_usuario)\n",
        "    return to_markdown(resposta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDpx7uTKSjzd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "c2ab0b69-d06e-4b95-9865-40bf6eb06eee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \n>       👋 Olá! Sou o Empreend.AI, seu novo sócio digital! Para te ajudar de forma mais personalizada,\n>       quero te fazer 4 perguntas essenciais sobre sua empresa e seu estilo de trabalho. Podemos começar?\n>       Ou prefere ir direto ao ponto e me dizer em que posso te ajudar HOJE?\n> \n>       "
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Bloco inicial: apresentação e decisão\n",
        "ola = f\"\"\"\n",
        "      👋 Olá! Sou o Empreend.AI, seu novo sócio digital! Para te ajudar de forma mais personalizada,\n",
        "      quero te fazer 4 perguntas essenciais sobre sua empresa e seu estilo de trabalho. Podemos começar?\n",
        "      Ou prefere ir direto ao ponto e me dizer em que posso te ajudar HOJE?\n",
        "\n",
        "      \"\"\"\n",
        "display(to_markdown(ola))\n",
        "\n",
        "resposta_inicial = input(\"✏️ Digite 'começar' ou 'direto':\\n> \").lower()\n",
        "\n",
        "if resposta_inicial == \"direto\":\n",
        "    perfil_usuario = {\"modo_direto\": True}\n",
        "    print(\"👍 Perfeito! Pode me dizer com o que você precisa de ajuda agora.\")\n",
        "else:\n",
        "    respostas_usuario = entrevista_interativa()\n",
        "    perfil_usuario = agente_classificador_de_perfil(respostas_usuario)\n",
        "    agente_apresentador_de_perfil(perfil_usuario)\n",
        "\n",
        "# Loop contínuo da conversa\n",
        "print(\"\\n🚀 Agora você pode fazer seus pedidos. Digite 'sair' para encerrar.\\n\")\n",
        "comandos_sair = {\"sair\", \"exit\", \"quit\", \"parar\", \"encerrar\", \"fim\", \"tchau\"}\n",
        "\n",
        "while True:\n",
        "    pedido = input(\"> \").strip()\n",
        "    if pedido.lower() in comandos_sair:\n",
        "        print(\"Até logo! Foi um prazer ajudar você. 🌟\")\n",
        "        break\n",
        "\n",
        "    # Dispara busca se a frase for maior que 4 palavras (para evitar buscas inúteis)\n",
        "    if len(pedido.split()) > 4:\n",
        "        busca = buscar_com_google_gemini(pedido)\n",
        "        prompt_completo = f\"{pedido}\\n\\nResultados da busca atual:\\n{busca}\"\n",
        "    else:\n",
        "        prompt_completo = pedido\n",
        "\n",
        "    # Aqui você pode chamar sua função/agent personalizada que responde baseado no prompt completo\n",
        "    # Exemplo fictício, substitua pela sua implementação:\n",
        "    resposta = agente_executor_personalizado(prompt_completo, perfil_usuario)\n",
        "\n",
        "    display(resposta)\n",
        "\n",
        "\"\"\"while True:\n",
        "    pedido = input(\"> \").strip()\n",
        "    if pedido.lower() in comandos_sair:\n",
        "        print(\"Até logo! Foi um prazer ajudar você. 🌟\")\n",
        "        break\n",
        "\n",
        "    # Busca SEMPRE que o pedido tiver conteúdo relevante\n",
        "    if len(pedido.split()) > 4:  # Evita busca para mensagens muito curtas\n",
        "        busca = buscar_com_google_gemini(pedido)\n",
        "        prompt_completo = f\"{pedido}\\n\\nResultados da busca atual:\\n{busca}\"\n",
        "    else:\n",
        "        prompt_completo = pedido\n",
        "\n",
        "    resposta = agente_executor_personalizado(prompt_completo, perfil_usuario)\n",
        "    display(resposta)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATpmfdiHNql8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}