{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuvK_vaIPzTp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KFAPmGPtO_LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbde7d2e-09c1-4e51-c08a-521f48c640e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/232.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/95.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m217.1/217.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Instalar as bibliotecas necess√°rias (rode no colab)\n",
        "!pip install -U google-genai -q\n",
        "!pip install -q google-adk\n",
        "\n",
        "# Importa√ß√µes e configura√ß√£o\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai  # Biblioteca oficial para Gemini (genai)\n",
        "\n",
        "# Configura√ß√£o dos tools dispon√≠veis no modelo Gemini (s√≥ o nome da ferramenta)\n",
        "TOOLS = [\"google_search\"]\n",
        "\n",
        "# Quebrando o Texto por Linhas\n",
        "from IPython.display import HTML, Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "# Configurar chave da API do Gemini\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "\n",
        "# Importa√ß√µes do ADK\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.genai import types # This import is for types, not the main model\n",
        "from datetime import date\n",
        "import ast  # Seguran√ßa ao avaliar dicion√°rios do agente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xIAPOdOrPJ0n"
      },
      "outputs": [],
      "source": [
        "#fun√ß√£o auxiliar chamar agentes\n",
        "def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    session_service = InMemorySessionService()\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=\"user1\", session_id=\"session1\")\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "    final_response = \"\"\n",
        "    for event in runner.run(user_id=\"user1\", session_id=\"session1\", new_message=content):\n",
        "        if event.is_final_response():\n",
        "            for part in event.content.parts:\n",
        "                if part.text:\n",
        "                    final_response += part.text + \"\\n\"\n",
        "    return final_response\n",
        "\n",
        "# MEM√ìRIA GLOBAL (pode ser exportada para JSON, Planilha, etc.)\n",
        "perfil_usuario = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "E3guyPTPOFYs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DICION√ÅRIO\n",
        "# melhorar: criar em um arquivo externo .py\n",
        "metodos_produtividade = {\n",
        "    \"GTD\": {\n",
        "        \"organizacao\": [\"metas\", \"livre\"],\n",
        "        \"descricao\": (\n",
        "            \"O m√©todo Getting Things Done (GTD) foca em capturar todas as tarefas e compromissos \"\n",
        "            \"fora da mente, organiz√°-los em listas espec√≠ficas e revis√°-los regularmente para aumentar a produtividade.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"Liste todas as suas tarefas, categorize-as por contexto (ex: 'telefonemas', 'compras'), \"\n",
        "            \"e revise semanalmente para priorizar o que deve ser feito.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Todoist\", \"Evernote\", \"Notion\"]\n",
        "    },\n",
        "    \"Ivy Lee\": {\n",
        "        \"organizacao\": [\"metas\", \"time_blocking\"],\n",
        "        \"descricao\": (\n",
        "            \"M√©todo simples que prioriza at√© 6 tarefas importantes para o dia seguinte, \"\n",
        "            \"executando-as em ordem, ajudando a focar no essencial.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"No final do dia, escreva as 6 tarefas mais importantes para amanh√£, \"\n",
        "            \"comece pela primeira e s√≥ passe para a pr√≥xima quando terminar.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Bloco de notas\", \"Todoist\"]\n",
        "    },\n",
        "    \"Pomodoro\": {\n",
        "        \"organizacao\": [\"time_blocking\", \"livre\"],\n",
        "        \"descricao\": (\n",
        "            \"Trabalhar em blocos de tempo focado de 25 minutos, seguidos por pausas curtas, \"\n",
        "            \"aumentando a concentra√ß√£o e prevenindo fadiga.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"Configure um timer para 25 minutos e trabalhe sem distra√ß√µes. \"\n",
        "            \"Ap√≥s o alarme, fa√ßa uma pausa de 5 minutos. Repita 4 vezes e fa√ßa uma pausa maior.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Pomodone\", \"TomatoTimer\", \"Forest\"]\n",
        "    },\n",
        "    \"Kanban\": {\n",
        "        \"organizacao\": [\"to_do\", \"livre\"],\n",
        "        \"descricao\": (\n",
        "            \"Sistema visual que organiza tarefas em colunas como 'A fazer', 'Fazendo' e 'Feito', \"\n",
        "            \"facilitando o acompanhamento do fluxo de trabalho.\"\n",
        "        ),\n",
        "        \"exemplo_uso\": (\n",
        "            \"Crie cart√µes para cada tarefa e mova-os entre as colunas conforme o progresso, \"\n",
        "            \"visualizando claramente o status das atividades.\"\n",
        "        ),\n",
        "        \"ferramentas\": [\"Trello\", \"Asana\", \"ClickUp\"]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "uRLXdOuEhdcT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Fun√ß√£o de busca usando Gemini com Google Search tool\n",
        "def buscar_com_google_gemini(query: str):\n",
        "    # Cria o modelo Gemini com a ferramenta google_search ativada\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name=\"gemini-1.5-pro-latest\",\n",
        "        tools=[{\"name\": \"google_search\"}]  # Apenas 'name' da ferramenta, sem 'type'\n",
        "    )\n",
        "    # Gera o conte√∫do usando o prompt e ativando a fun√ß√£o de busca\n",
        "    response = model.generate_content(query)\n",
        "    return response.text\"\"\"\n",
        "\n",
        "def buscar_com_google_gemini(query: str):\n",
        "  model = genai.GenerativeModel(\n",
        "      model_name=\"gemini-1.5-pro-latest\",\n",
        "      tools=[{\"name\": \"google_search\"}]\n",
        "  )\n",
        "\n",
        "  # Limita tamanho do prompt a 500 caracteres (ajust√°vel)\n",
        "  query_limpa = query.strip()[:500]\n",
        "\n",
        "  try:\n",
        "      response = model.generate_content(query_limpa)\n",
        "      return response.text\n",
        "  except Exception as e:\n",
        "      return f\"Erro ao buscar: {e}\""
      ],
      "metadata": {
        "id": "vz3X8h_fpGJV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SeEq7lo5Ptu3"
      },
      "outputs": [],
      "source": [
        "# FUN√á√ÉO ENTREVISTA\n",
        "def entrevista_interativa():\n",
        "    respostas = {}\n",
        "\n",
        "    perguntas = {\n",
        "        \"segmento\": \"1. Qual √© o segmento principal da sua empresa? (Ex: Alimenta√ß√£o, Moda, Tecnologia, Servi√ßos, etc.)\",\n",
        "        \"tipo_negocio\": \"2. Seu tipo de neg√≥cio se encaixa mais como: e-commerce, venda de produtos f√≠sicos, presta√ß√£o de servi√ßos, consultoria, ou outro?\",\n",
        "        \"objetivo\": \"3. Qual √© o seu principal objetivo para o seu neg√≥cio neste momento? (Ex: Aumentar vendas, organizar minhas finan√ßas, melhorar meu marketing, otimizar meu tempo, etc.)\",\n",
        "        \"organizacao\": \"4. Pensando em como voc√™ geralmente lida com suas tarefas e seu tempo, qual das op√ß√µes abaixo descreve melhor seu estilo de produtividade?\\n\\\n",
        "a) Focado em metas\\nb) Organizado por tempo\\nc) Flex√≠vel e adapt√°vel\\nd) Orientado por listas\"\n",
        "    }\n",
        "    for chave, pergunta in perguntas.items():\n",
        "        resposta = input(pergunta + \"\\n> \")\n",
        "        respostas[chave] = resposta\n",
        "\n",
        "    return respostas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JNrZ2Qn3UTpv"
      },
      "outputs": [],
      "source": [
        "# AGENTE 1 - PERFILADOR\n",
        "# melhorar: coletar informa√ß√µes durante qualquer intera√ß√£o (de forma dinamica) para adicionar novas variaveis dentro de perfil\n",
        "def agente_classificador_de_perfil(respostas):\n",
        "    \"\"\"\n",
        "    Interpreta e classifica as respostas da entrevista_interativa() com base em perfis padronizados.\n",
        "    Retorna um dicion√°rio com labels estruturados.\n",
        "    \"\"\"\n",
        "    perfil = {}\n",
        "\n",
        "    # Segmento (mant√©m texto original do usu√°rio)\n",
        "    segmento = respostas.get(\"segmento\", \"\").strip()\n",
        "    perfil[\"segmento\"] = segmento\n",
        "\n",
        "    #Tipo de neg√≥cio\n",
        "    tipo = respostas.get(\"tipo_negocio\", \"\").lower()\n",
        "    # Categorias com palavras relacionadas\n",
        "    palavras_produto = [\"produto\", \"produtos\", \"fabrica√ß√£o\", \"fabricacao\", \"industrial\"]\n",
        "    palavras_servico = [\"servi√ßo\", \"servico\", \"presta√ß√£o\", \"consultoria\", \"atendimento\", \"freelancer\"]\n",
        "    palavras_online = [\"e-commerce\", \"loja virtual\", \"digital\", \"online\", \"marketplace\"]\n",
        "    palavras_fisico = [\"f√≠sico\", \"fisico\", \"loja f√≠sica\", \"presencial\", \"ponto de venda\"]\n",
        "\n",
        "    # Verifica a qual categoria pertence\n",
        "    if any(p in tipo for p in palavras_produto):\n",
        "        perfil[\"tipo_negocio\"] = \"produto\"\n",
        "    elif any(p in tipo for p in palavras_servico):\n",
        "        perfil[\"tipo_negocio\"] = \"servico\"\n",
        "    elif any(p in tipo for p in palavras_online):\n",
        "        perfil[\"tipo_negocio\"] = \"online\"\n",
        "    elif any(p in tipo for p in palavras_fisico):\n",
        "        perfil[\"tipo_negocio\"] = \"fisico\"\n",
        "    else:\n",
        "        perfil[\"tipo_negocio\"] = \"hibrido\"\n",
        "\n",
        "    # Objetivo\n",
        "    objetivo = respostas.get(\"objetivo\", \"\").lower()\n",
        "    if \"vender\" in objetivo:\n",
        "        perfil[\"objetivo\"] = \"vender_mais\"\n",
        "    elif \"organizar\" in objetivo or \"rotina\" in objetivo:\n",
        "        perfil[\"objetivo\"] = \"organizar_rotina\"\n",
        "    elif \"tempo\" in objetivo or \"automatizar\" in objetivo:\n",
        "        perfil[\"objetivo\"] = \"ganhar_tempo\"\n",
        "    else:\n",
        "        perfil[\"objetivo\"] = \"neutro\"\n",
        "\n",
        "    # Estilo de organiza√ß√£o\n",
        "    org = respostas.get(\"organizacao\", \"\").lower().strip()\n",
        "\n",
        "    if org.startswith(\"b\"):\n",
        "        perfil[\"organizacao\"] = \"time_blocking\"\n",
        "    elif org.startswith(\"a\"):\n",
        "        perfil[\"organizacao\"] = \"metas\"\n",
        "    elif org.startswith(\"d\"):\n",
        "        perfil[\"organizacao\"] = \"to_do\"\n",
        "    elif org.startswith(\"c\"):\n",
        "        perfil[\"organizacao\"] = \"livre\"\n",
        "    else:\n",
        "        perfil[\"organizacao\"] = \"indefinido\"\n",
        "\n",
        "    def adicionar_metodo(perfil, metodos_produtividade):\n",
        "      # Seleciona os m√©todos baseado na organiza√ß√£o\n",
        "      organizacao = perfil.get(\"organizacao\", \"\")\n",
        "      metodos_para_organizacao = [\n",
        "          metodo for metodo, dados in metodos_produtividade.items()\n",
        "          if organizacao in dados[\"perfil_indicado\"]\n",
        "      ]\n",
        "      # Atualiza o perfil com os m√©todos encontrados ou usa [\"GTD\"] como padr√£o\n",
        "      perfil[\"metodos_produtividade\"] = metodos_para_organizacao or [\"GTD\"]\n",
        "\n",
        "    return perfil\n",
        "    print (to_markdown(perfil))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "K72E_M_OSjIz"
      },
      "outputs": [],
      "source": [
        "# AGENTE 2 APRESENTADOR\n",
        "def agente_apresentador_de_perfil(perfil_usuario):\n",
        "    agente = Agent(\n",
        "        name=\"agente_apresentador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Voc√™ √© um assistente pessoal emp√°tico e inteligente.\n",
        "        Sua miss√£o √© ler o perfil de um empreendedor e:\n",
        "\n",
        "        1. Fazer um coment√°rio breve, simp√°tico e acolhedor sobre o estilo da pessoa.\n",
        "        2. Mostrar que voc√™ compreende o contexto e o ramo de atua√ß√£o dela.\n",
        "        3. Reafirmar que todas as suas respostas a partir de agora ser√£o adaptadas a esse perfil.\n",
        "        4. Perguntar, com naturalidade e leveza, o que ela precisa resolver HOJE.\n",
        "\n",
        "        Use linguagem clara, respeitosa e personalizada.\n",
        "        Adapte o tom da resposta conforme o estilo de foco ou organiza√ß√£o do usu√°rio.\n",
        "        Pode usar emojis se o perfil sugerir algo mais informal.\n",
        "        Evite parecer rob√≥tico. Soe como algu√©m que entende gente de verdade.\n",
        "        \"\"\",\n",
        "        description=\"Apresentador de perfil e primeiro contato amig√°vel com o usu√°rio\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"Perfil do usu√°rio:\\n{perfil_usuario}\"\n",
        "    print(\"üåü Apresentando o perfil e iniciando o atendimento personalizado...\\n\")\n",
        "    resposta = call_agent(agente, prompt)\n",
        "    print(resposta)\n",
        "    return to_markdown(resposta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lWcA4tcZcnNK"
      },
      "outputs": [],
      "source": [
        "# AGENTE 3 EXECUTOR\n",
        "def agente_executor_personalizado(pedido_usuario: str, perfil: dict) -> str:\n",
        "    agente = Agent(\n",
        "        name=\"agente_executor_personalizado\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        # melhorar: data dinamica\n",
        "        instruction=f\"\"\" Voc√™ √© um assistente pr√°tico e vision√°rio, feito para apoiar pequenos empreendedores brasileiros com base nas tend√™ncias mais recentes (at√© maio de 2025)\n",
        "         e orienta√ß√µes do Sebrae. Use um tom encorajador e, quando apropriado, um toque de humor leve para motivar.\n",
        "\n",
        "        ‚Üí Baseie suas respostas no perfil do usu√°rio:\n",
        "          - Organiza√ß√£o: {perfil.get('organizacao')}\n",
        "          - Tipo de neg√≥cio: {perfil.get('tipo_negocio')}\n",
        "          - Segmento: {perfil.get('segmento')}\n",
        "          - Objetivo principal: {perfil.get('objetivo')}\n",
        "          - Metodos de produtividade recomendados: {perfil.get('metodos_produtividade')}\n",
        "\n",
        "        ‚Üí Adapte sua comunica√ß√£o com base nesses perfis. Use uma tabela interna para modular tom, formato e sugest√µes.\n",
        "\n",
        "        ‚Üí Sempre que o tema permitir, pergunte sutilmente sobre a√ß√µes sustent√°veis no neg√≥cio. Enfatize que empresas comprometidas com o planeta tendem a liderar o futuro do mercado.\n",
        "\n",
        "        ‚Üí Seja sempre:\n",
        "          - Claro e conciso (respostas curtas, sem floreios)\n",
        "          - Personalizado (nada gen√©rico)\n",
        "          - Focado em a√ß√£o pr√°tica, metas e acompanhamento\n",
        "          - Atualizado com dados do Sebrae, tend√™ncias digitais e comportamento do consumidor\n",
        "\n",
        "        ‚Üí Incentive:\n",
        "          - Participa√ß√£o em conselhos e redes de apoio locais\n",
        "          - Cursos e capacita√ß√µes\n",
        "          - Inova√ß√£o constante\n",
        "          - O associativismo como caminho de crescimento\n",
        "\n",
        "       ‚Üí Se o pedido estiver incompleto ou muito geral, utilize seu conhecimento sobre o perfil e incentive o usu√°rio a dar mais contexto com leveza ‚Äî mas continue ajudando com o que for poss√≠vel.\n",
        "      ‚Üí Se o metodo de produtividade do usu√°rio for conhecido, voc√™ pode sugerir um m√©todo que combine com ele e com a solicita√ß√£o que ele te fez. Use linguagem leve, como: Nesse caso, talvez o m√©todo X funcione bem pra voc√™.\n",
        "      Pedido do usu√°rio: \"{pedido_usuario}\"\n",
        "        \"\"\",\n",
        "        description=\"Executor Personalizado: adapta respostas e sugest√µes ao perfil do empreendedor\"\n",
        "    )\n",
        "\n",
        "    resposta = call_agent(agente, pedido_usuario)\n",
        "    return to_markdown(resposta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDpx7uTKSjzd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "c2ab0b69-d06e-4b95-9865-40bf6eb06eee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> \n>       üëã Ol√°! Sou o Empreend.AI, seu novo s√≥cio digital! Para te ajudar de forma mais personalizada,\n>       quero te fazer 4 perguntas essenciais sobre sua empresa e seu estilo de trabalho. Podemos come√ßar?\n>       Ou prefere ir direto ao ponto e me dizer em que posso te ajudar HOJE?\n> \n>       "
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Bloco inicial: apresenta√ß√£o e decis√£o\n",
        "ola = f\"\"\"\n",
        "      üëã Ol√°! Sou o Empreend.AI, seu novo s√≥cio digital! Para te ajudar de forma mais personalizada,\n",
        "      quero te fazer 4 perguntas essenciais sobre sua empresa e seu estilo de trabalho. Podemos come√ßar?\n",
        "      Ou prefere ir direto ao ponto e me dizer em que posso te ajudar HOJE?\n",
        "\n",
        "      \"\"\"\n",
        "display(to_markdown(ola))\n",
        "\n",
        "resposta_inicial = input(\"‚úèÔ∏è Digite 'come√ßar' ou 'direto':\\n> \").lower()\n",
        "\n",
        "if resposta_inicial == \"direto\":\n",
        "    perfil_usuario = {\"modo_direto\": True}\n",
        "    print(\"üëç Perfeito! Pode me dizer com o que voc√™ precisa de ajuda agora.\")\n",
        "else:\n",
        "    respostas_usuario = entrevista_interativa()\n",
        "    perfil_usuario = agente_classificador_de_perfil(respostas_usuario)\n",
        "    agente_apresentador_de_perfil(perfil_usuario)\n",
        "\n",
        "# Loop cont√≠nuo da conversa\n",
        "print(\"\\nüöÄ Agora voc√™ pode fazer seus pedidos. Digite 'sair' para encerrar.\\n\")\n",
        "comandos_sair = {\"sair\", \"exit\", \"quit\", \"parar\", \"encerrar\", \"fim\", \"tchau\"}\n",
        "\n",
        "while True:\n",
        "    pedido = input(\"> \").strip()\n",
        "    if pedido.lower() in comandos_sair:\n",
        "        print(\"At√© logo! Foi um prazer ajudar voc√™. üåü\")\n",
        "        break\n",
        "\n",
        "    # Dispara busca se a frase for maior que 4 palavras (para evitar buscas in√∫teis)\n",
        "    if len(pedido.split()) > 4:\n",
        "        busca = buscar_com_google_gemini(pedido)\n",
        "        prompt_completo = f\"{pedido}\\n\\nResultados da busca atual:\\n{busca}\"\n",
        "    else:\n",
        "        prompt_completo = pedido\n",
        "\n",
        "    # Aqui voc√™ pode chamar sua fun√ß√£o/agent personalizada que responde baseado no prompt completo\n",
        "    # Exemplo fict√≠cio, substitua pela sua implementa√ß√£o:\n",
        "    resposta = agente_executor_personalizado(prompt_completo, perfil_usuario)\n",
        "\n",
        "    display(resposta)\n",
        "\n",
        "\"\"\"while True:\n",
        "    pedido = input(\"> \").strip()\n",
        "    if pedido.lower() in comandos_sair:\n",
        "        print(\"At√© logo! Foi um prazer ajudar voc√™. üåü\")\n",
        "        break\n",
        "\n",
        "    # Busca SEMPRE que o pedido tiver conte√∫do relevante\n",
        "    if len(pedido.split()) > 4:  # Evita busca para mensagens muito curtas\n",
        "        busca = buscar_com_google_gemini(pedido)\n",
        "        prompt_completo = f\"{pedido}\\n\\nResultados da busca atual:\\n{busca}\"\n",
        "    else:\n",
        "        prompt_completo = pedido\n",
        "\n",
        "    resposta = agente_executor_personalizado(prompt_completo, perfil_usuario)\n",
        "    display(resposta)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATpmfdiHNql8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}